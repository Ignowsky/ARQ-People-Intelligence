# ğŸ“Š ARQ-People Intelligence: Pipeline de Engenharia de Dados de RH

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-12%2B-336791?style=for-the-badge&logo=postgresql)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-Red-red?style=for-the-badge)
![Azure DevOps](https://img.shields.io/badge/Azure%20DevOps-0078D7?style=for-the-badge&logo=azure-devops)

## ğŸ“‹ VisÃ£o Geral
Este projeto consiste em um pipeline de **Engenharia de Dados (ETL)** robusto desenvolvido em Python para centralizar, limpar e estruturar dados de Recursos Humanos. O sistema orquestra a ingestÃ£o de dados de duas fontes distintas:

1.  **Arquivos NÃ£o-Estruturados (PDF):** Holerites, Recibos de FÃ©rias e 13Âº SalÃ¡rio (OCR/Regex).
2.  **API Externa (SÃ³lides):** Dados cadastrais ricos e benefÃ­cios (REST).

O objetivo final Ã© alimentar um Data Warehouse (PostgreSQL) modelado em **Star Schema** para anÃ¡lises de *People Analytics* (Turnover, Headcount, Custo de Folha, etc.).

---

## ğŸ—ï¸ Arquitetura do Projeto

O projeto segue uma arquitetura modular baseada em **Separation of Concerns (SoC)**, onde cada etapa do ETL possui responsabilidade Ãºnica.

```text
/
â”œâ”€â”€ input/                 # [Staging] Ãrea de entrada dos PDFs brutos.
â”œâ”€â”€ output/                # [Transient] Ãrea de CSVs processados para auditoria/debug.
â”œâ”€â”€ src/                   # NÃºcleo da Engenharia
â”‚   â”œâ”€â”€ database.py        # Factory de conexÃ£o (Singleton pattern).
â”‚   â”œâ”€â”€ extract.py         # IngestÃ£o (OCR via pdfplumber + Requests API).
â”‚   â”œâ”€â”€ transform.py       # Limpeza, Tipagem (Pandas) e Regras de NegÃ³cio.
â”‚   â”œâ”€â”€ load.py            # PersistÃªncia (Upserts, DDL e Tratamento de Erros).
â”‚   â”œâ”€â”€ utils.py           # SanitizaÃ§Ã£o (Texto e Moeda).
â”‚   â””â”€â”€ constants.py       # Metadados e DicionÃ¡rio de Rubricas.
â”œâ”€â”€ main.py                # Orquestrador (Entry Point).
â”œâ”€â”€ renomear_arquivo.py    # UtilitÃ¡rio de padronizaÃ§Ã£o de arquivos.
â””â”€â”€ .env                   # VariÃ¡veis de ambiente (SeguranÃ§a).
```
----
## âš™ï¸ Fluxo da Arquitetura do Projeto
![Fluxo de Arquitetura](./assets/Untitled diagram-2025-12-10-134210.png)
----

# ğŸš€ Detalhamento TÃ©cnico dos MÃ³dulos

## 1. ExtraÃ§Ã£o (```src/extract.py```)


- **PDFs** : Utiliza a biblioteca ```pdfplumber``` para extraÃ§Ã£o de texto bruto. **Aplica ExpressÃµes Regulares (Regex)** complexas para identificar padrÃµes de layout variÃ¡veis (Holerite Mensal vs. Recibo de FÃ©rias).

  - EstratÃ©gia de Fallback: O extrator possui mÃºltiplas camadas de regex. Se nÃ£o encontrar o padrÃ£o "CompetÃªncia: MM/AAAA", busca por "Data de Pagamento" ou "PerÃ­odo de Gozo".
- **API**: Implementa paginaÃ§Ã£o automÃ¡tica (```while loop```) para iterar sobre todos os endpoints da API da Solides, garantindo a extraÃ§Ã£o completa da base de colaboradores.

## 2. TransformaÃ§Ã£o (```src/transform.py```)

Focada em **Data Quality** e **Tipagem Forte.**

- **SanitizaÃ§Ã£o**: Converte strings monetÃ¡rias brasileiras ('R$ 1.000,00') para objetos ``Decimal`` ou ``float`` limpos.

**Tratamento de Datas**: Converte strings para objetos ``datetime.date``, transformando valores invÃ¡lidos (``NaT``, ``nan``) explicitamente em ``None`` (NULL) para evitar erros no banco.

**Enriquecimento**: Padroniza nomes de rubricas baseados em um dicionÃ¡rio de-para (``constants.py``).

## 3. Carga (``src/load.py``)

Utiliza SQLAlchemy e SQL puro para mÃ¡xima performance e controle.

**IdempotÃªncia**: A carga de fatos utiliza a estratÃ©gia *Delete-Insert* baseada na competÃªncia. Isso permite reprocessar um mÃªs inteiro sem duplicar dados.

**SCD Tipo 1 (Upsert)**: A dimensÃ£o de colaboradores utiliza ``INSERT ... ON CONFLICT DO UPDATE`` para garantir que o cadastro esteja sempre atualizado, mantendo o ID imutÃ¡vel.

**SeguranÃ§a de Tipos**: Implementa funÃ§Ãµes ``safe_cast`` no SQL (``CAST(NULLIF(..., '') AS NUMERIC``)) para blindar o banco contra strings vazias ou caracteres sujos vindos da fonte.


### 4. UtilitÃ¡rios (`src/utils.py`)
MÃ³dulo transversal de funÃ§Ãµes auxiliares (Helpers) reutilizÃ¡veis:
* **Limpeza de Texto (`clean_text_series`):** HigienizaÃ§Ã£o "pesada" de strings. Remove quebras de linha (`\n`), tabulaÃ§Ãµes (`\t`), caracteres invisÃ­veis de PDF (`\xa0`) e normaliza espaÃ§os mÃºltiplos.
* **NormalizaÃ§Ã£o MonetÃ¡ria (`limpar_valor_moeda`):** Resolve o problema de localizaÃ§Ã£o (Locale PT-BR). Transforma formatos complexos como `R$ 1.500,50` ou `1.000,00` em decimais limpos (`1500.50`) prontos para cÃ¡lculo matemÃ¡tico e inserÃ§Ã£o no banco.
---

# ğŸ”’ PolÃ­tica de SeguranÃ§a e RetenÃ§Ã£o de Dados

Este pipeline lida com Dados Pessoais SensÃ­veis (LGPD). As seguintes regras sÃ£o aplicadas via cÃ³digo e processo:

1. **Pasta ``input/`` (PDFs)**: Destinada apenas para leitura momentÃ¢nea. ApÃ³s a execuÃ§Ã£o do pipeline e validaÃ§Ã£o, os arquivos devem ser excluÃ­dos ou movidos para um armazenamento frio seguro (Cold Storage/S3).

2. **Pasta ``output/`` (CSVs)**: Arquivos gerados apenas para debug e transporte (Staging). Devem ser **excluÃ­dos** imediatamente apÃ³s a confirmaÃ§Ã£o da carga no banco.

3. **Credenciais**: Nenhuma senha Ã© hardcoded. Tudo Ã© gerenciado via variÃ¡veis de ambiente (``.env``).

---
# âš™ï¸ Como Executar
### PrÃ©-requisitos
- Python 3.9+
- PostgreSQL 12+
- DependÃªncias listadas em requirements.txt

### Passo a Passo

1. Configure o arquivo ```.env``` na raiz:
    ```text
    DB_USER=postgres
    DB_PASS=sua_senha
    DB_HOST=localhost
    DB_PORT=5432
    DB_NAME=dw_rh
    DB_SCHEMA=fopag_prod
    SOLIDES_API_TOKEN=seu_token
    ```
2. Coloque os PDFs na pasta ``input/.``.
3. (Opcional) Padronize os nomes dos arquivos:
   ```bash
   python renomear_arquivo.py
   ```
4. Execute o Pipeline principal:
   ```bash
   python main.py
   ```
5. **VerificaÃ§Ã£o:** Acompanhe os logs no terminal. No final, verifique as tabelas `fato_folha_consolidada` e `dim_colaboradores`